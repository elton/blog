---
layout: post
title: '分布式文件系统MFS、Ceph、GlusterFS、Lustre的比较'
date: 2011-12-29
wordpress_id: 848
permalink: /blogs/848
comments: true
categories:
- Linux
tags:
- 分布式存储

---
<table border="1" cellspacing="0" cellpadding="0">
<tbody>
<tr>
<td valign="top">&nbsp;</td>
<td valign="top">**MooseFS(MFS)**</td>
<td valign="top">**Ceph**</td>
<td valign="top">**GlusterFS**</td>
<td valign="top">**Lustre**</td>
</tr>
<tr>
<td valign="top">**Metadata server**</td>
<td valign="top">单个MDS。存在单点故障和瓶颈。</td>
<td valign="top">多个MDS，不存在单点故障和瓶颈。MDS可以扩展，不存在瓶颈。</td>
<td valign="top">无，不存在单点故障。靠运行在各个节点上的动态算法来代替MDS,不需同步元数据,无硬盘I/O瓶颈。</td>
<td valign="top">双MDS(互相备份)。MDS不可以扩展，存在瓶颈。</td>
</tr>
<tr>
<td valign="top">**FUSE**</td>
<td valign="top">支持</td>
<td valign="top">支持</td>
<td valign="top">支持</td>
<td valign="top">支持</td>
</tr>
<tr>
<td valign="top">**访问接口**</td>
<td valign="top">POSIX</td>
<td valign="top">POSIX</td>
<td valign="top">POSIX</td>
<td valign="top">POSIX/MPI</td>
</tr>
<tr>
<td valign="top">**文件分布/数据分布**</td>
<td valign="top">文件被分片，数据块保存在不同的存储服务器上。</td>
<td valign="top">文件被分片，每个数据块是一个对象。对象保存在不同的存储服务器上。</td>
<td valign="top">Cluster Translators(GlusterFS集群存储的核心)包括AFR、DHT（和Stripe三种类型。

AFR相当于RAID1，每个文件都被复制到多个存储节点上。Stripe相当于RAID0，文件被分片，数据被条带化到各个存储节点上。

Translators可以组合，即AFR和stripe可以组成RAID10，实现高性能和高可用。</td>
<td valign="top">可以把大文件分片并以类似RAID0的方式分散存储在多个存储节点上。</td>
</tr>
<tr>
<td valign="top">**冗余保护/副本**</td>
<td valign="top">多副本</td>
<td valign="top">多副本</td>
<td valign="top">镜像</td>
<td valign="top">无</td>
</tr>
<tr>
<td valign="top">**数据可靠性**</td>
<td valign="top">由数据的多副本提供可靠性。</td>
<td valign="top">由数据的多副本提供可靠性。</td>
<td valign="top">由镜像提供可靠性。</td>
<td valign="top">由存储节点上的RAID1或RAID5/6提供可靠性。假如存储节点失效，则数据不可用。</td>
</tr>
<tr>
<td valign="top">**备份**</td>
<td valign="top">&nbsp;</td>
<td valign="top">&nbsp;</td>
<td valign="top">&nbsp;</td>
<td valign="top">提供备份工具。支持远程备份。</td>
</tr>
<tr>
<td valign="top">**故障恢复**</td>
<td valign="top">手动恢复</td>
<td valign="top">当节点失效时，自动迁移数据、重新复制副本。</td>
<td valign="top">当节点、硬件、磁盘、网络发生故障时，系统会自动处理这些故障，管理员不需介入。</td>
<td valign="top">无</td>
</tr>
<tr>
<td valign="top">**扩展性**</td>
<td valign="top">增加存储服务器，可以提高容量和文件操作性能。但是由于不能增加MDS，因此元数据操作性能不能提高，是整个系统的瓶颈。</td>
<td valign="top">可以增加元数据服务器和存储节点。容量可扩展。文件操作性能可扩展。元数据操作性能可扩展。</td>
<td valign="top">容量可扩展。</td>
<td valign="top">可增加存储节点，提高容量可文件操作性能，但是由于不能增加MDS，因此元数据操作性能不能提高，是整个系统的瓶颈。</td>
</tr>
<tr>
<td valign="top">**安装/部署**</td>
<td valign="top">简单</td>
<td valign="top">简单</td>
<td valign="top">简单</td>
<td valign="top">复杂。而且Lustre严重依赖内核，需要重新编译内核。</td>
</tr>
<tr>
<td valign="top">**开发语言**</td>
<td valign="top">C</td>
<td valign="top">C++</td>
<td valign="top">C</td>
<td valign="top">C</td>
</tr>
<tr>
<td valign="top">**适合场景**</td>
<td valign="top">大量小文件读写</td>
<td valign="top">小文件</td>
<td valign="top"><a name="_Toc288579612"></a><a name="_Toc288579827"></a><a name="_Toc288579902"></a><a name="_Toc288580250"></a>适合大文件。

<a name="_Toc288580250"></a>对于小文件，无元数据服务设计解决了元数据的问题。但GlusterFS并没有在I/O方面作优化，在存储服务器底层文件系统上仍然是大量小文件，本地文件系统元数据访问是瓶颈，数据分布和并行性也无法充分发挥作用。因此，GlusterFS的小文件性能还存在很大优化空间。</td>
<td valign="top">大文件读写</td>
</tr>
<tr>
<td valign="top">**产品级别**</td>
<td valign="top">小型</td>
<td valign="top">中型</td>
<td valign="top">中型</td>
<td valign="top">重型</td>
</tr>
<tr>
<td valign="top">**应用**</td>
<td valign="top">国内较多</td>
<td valign="top">无</td>
<td valign="top">较多用户使用</td>
<td valign="top">HPC领域。</td>
</tr>
<tr>
<td valign="top">**优缺点**</td>
<td valign="top">实施简单，但是存在单点故障。</td>
<td valign="top">不稳定，目前还在实验阶段，不适合于生产环境。</td>
<td valign="top">无元数据服务器，堆栈式架构(基本功能模块可以进行堆栈式组合，实现强大功能)。具有线性横向扩展能力。

&nbsp;

由于没有元数据服务器，因此增加了客户端的负载，占用相当的CPU和内存。

但遍历文件目录时，则实现较为复杂和低效，需要搜索所有的存储节点。因此不建议使用较深的路径。</td>
<td valign="top">很成熟、很庞大。</td>
</tr>
</tbody>
</table>

摘自<a href="http://blog.csdn.net/metaxen/article/details/7108958" title="存储实验室" target="_blank">存储实验室</a>
